{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "013d33d5",
   "metadata": {},
   "source": [
    "# Detecting Potential Adverse Drug Reactions Using a Deep Neural Network Model\n",
    "\n",
    "(Note -- this paper is different than the initial 3 project selection submitted since data was inaccessible across all 3 paper)\n",
    "\n",
    "## Intro\n",
    "\n",
    "On record, there are more than 2 million serious ADRs (adverse drug reactions) that occur amongst hospitalized patients which led to more than 100k deaths each year. Unfortunately since >90% of these ADRs go unreported, there lacks sufficient data for healthcare profession to property identify or predict potential ADRs.  This paper attempts to and focuses on using DNN to automatically detect potential ADR (adverse drug reactions) of a particular drug given its biological structures and other relevant infos with 2 goals: One is to idenfiy the potential ADRs of a drug given the history data adn context, and the other being predicting the possible ADRs of a new drug\n",
    "\n",
    "\n",
    "This paper used a diverse sources of data to help identify and predict ADR. This includes clinical trials, electronic meidcal records, biomedical literature, chemical/molecular pathways of drugs.. all with handcrafted and careful feature selection. The paper also experimented with a number of classical ML models alongside DNN models to better compare and evaluate their relative performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c34b80",
   "metadata": {},
   "source": [
    "## Scope of Reproducibility\n",
    "\n",
    "The scope of this first project draft is to build a MVP of the model using a subset of everything. This includes a subset of the data -- which means, instead of using both 2009 and 2012 data from SIDER as the training set, we will be using a subset of the 2009 data to start with. In addiion to that, we will also be using a subset of the input features to first test out the model and reduce the complexity-- this means that instead of using all of the features listed in the paper including biological, chemical, literature... findings of the drug, we will be focusing on using the chemical properties for the time being. (Note: This will indeed influence the accuracy and precision of the model training, but the whole goal is to make sure the base code run as is). Lastly, we will also be focusing on building one single model instead of reproing all model listed in the paper -- this means we will be focusing on using a basic RNN model instead of building out SVM, naives bayse.. etc etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4edeb370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94cee0a",
   "metadata": {},
   "source": [
    "## Dependencies and pretrained model:\n",
    "\n",
    "Not applicable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577c1dbb",
   "metadata": {},
   "source": [
    "## Methodology: Data Description & Pre-processing:\n",
    "\n",
    "The data required for this paper spawn across multiple places. For the scope of this project, we'd went to the following 3 places to retrieve the data (please see reference section below for actual instructions around data access):\n",
    "\n",
    "1) SIDER -- from SIDER, we first downloaded a copy of the 2009 drug record and their relevant ADRs. This represents the Y record; and \n",
    "\n",
    "2) PubChem -- from PubChem, we downaloaded a copy of the 'chemical & physical properties' of the drugs. This is part of the X record\n",
    "\n",
    "3) DrugBank -- from DrugBank, we requested for student research access for drug's bio properties. This consistutes part of the X feature set\n",
    "(^ However it's unfortunate that the data under the xml format was unconvertable to CSV for further processing, so having access to the data in XML format was rather pointless)\n",
    "\n",
    "(Note that the dimension of both X and Y in this project draft do not align with the original paper primarily because we'd reduced the scope of the data and the model)\n",
    "\n",
    "Below few cells are used to load, clean, and transform the data. As we could see, since the data resides from different databases. Plenty effort was spent in prepping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c3a597f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lomischen/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (16,19,23) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "#downloaded 2019 costart ADR data from SIDER and load it, transformed some of the data\n",
    "df_y = pd.read_csv('costart_adverse_effects.tsv', sep = '\\t')\n",
    "df_y['pubchem'] = df_y['pubchem']* (-1)\n",
    "df_y = df_y[['pubchem','drugname','ADR']] #filter it down to the drugname and ADR values\n",
    "\n",
    "#downloaded 2019 chem properties from pubchem and load it, select the columns of data of interest as per the paper\n",
    "df_x = pd.read_csv('PubChem_compound_properties.csv')\n",
    "df_x = df_x[['cid','mw','xlogp', 'hbonddonor', 'hbondacc', 'rotbonds', 'polararea', 'complexity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c48ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempting to find the intersect of the drugs from X and Y, filtering out records that don't have record with ADRs \n",
    "# or record of chemical & physical properties\n",
    "\n",
    "#Most of the following code are for pre processing and data cleaning\n",
    "\n",
    "intersect_keys = sorted(list(set(df_y['pubchem']) & set(df_x['cid'])))\n",
    "df_y = df_y[df_y['pubchem'].isin(intersect_keys)].sort_values(by = ['pubchem'])\n",
    "df_x = df_x[df_x['cid'].isin(intersect_keys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46a08766",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_cond = len(df_y['ADR'].unique())\n",
    "total_num_drug = len(df_y['drugname'].unique())\n",
    "Y = np.zeros((total_num_drug,total_num_cond))\n",
    "Y2 = np.zeros((total_num_drug,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92294c42",
   "metadata": {},
   "source": [
    "The followng cell focuses on creating a matrix/tensor of Y. It's one cell that takes up quite a bit of time. The hypothesis here is that the loop is rather computational expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64b22516",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_y = df_y.groupby('drugname').apply(lambda x:x.drop('drugname',axis=1).to_dict('list')).to_dict()\n",
    "ordered_cond = df_y['ADR'].sort_values().unique() #ordering the list of ADR conditions, different than sorted drug names\n",
    "unique_cid = df_x['cid']\n",
    "\n",
    "drug_counter = 0 #counting the unique drug from CID numerical order\n",
    "entry = 0 #counting the individual entries in the df_Y\n",
    "\n",
    "for i in df_y['drugname']:\n",
    "    if i == df_y['drugname'].unique()[drug_counter]:\n",
    "        index = np.where(ordered_cond == df_y.iloc[entry][2])[0][0]\n",
    "        #print(entry, drug_counter, i,df_y.iloc[entry][2], index)\n",
    "        Y[drug_counter][index] = 1\n",
    "        Y2[drug_counter] +=1\n",
    "        entry +=1\n",
    "    else:\n",
    "        drug_counter +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55399ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df_x.fillna(0)\n",
    "df_x = df_x.values.tolist()\n",
    "Y2 = Y2.tolist()\n",
    "Y2 = [item for sublist in Y2 for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68960ad2",
   "metadata": {},
   "source": [
    "## Implementation: Emulating the models built for in class projects\n",
    "\n",
    "The following few cells is an attempt to create a model using the ones we'd built in class. This is also the base model used for the research paper with slight modification/variable. Ideally there would be multiple models so that we could compare the results against one another\n",
    "\n",
    "We're also doing some modification on the base model. Instead of keeping the dimension of Y in its original form as is, I'd summed up the results and converted into a singular vector. This means that the embedded X are no longer mapping to binary results of Y but rather in the form of regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98c5834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class CustomDataset(Dataset): \n",
    "    def __init__(self, seqs, hfs):\n",
    "        self.x = seqs\n",
    "        self.y = hfs   \n",
    "    def __len__(self):\n",
    "        return len(self.y)    \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index],self.y[index])\n",
    "        \n",
    "\n",
    "dataset = CustomDataset(df_x, Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1518681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    sequences, labels = zip(*data)\n",
    "    y = torch.tensor(labels, dtype=torch.float)\n",
    "    x = torch.tensor(sequences, dtype=torch.long)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c4d5583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ln/tfnp7jpd7fqfkj79wjz21nb00000gn/T/ipykernel_30896/3764957986.py:4: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  x = torch.tensor(sequences, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "from torch.utils.data import DataLoader\n",
    "loader = DataLoader(dataset, batch_size=10, collate_fn = collate_fn)\n",
    "loader_iter = iter(loader)\n",
    "df_x, Y = next(loader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ef00ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of a batch x: torch.Size([10, 8])\n",
      "Shape of a batch y: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print('Shape of a batch x:', df_x.shape)\n",
    "print('Shape of a batch y:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e55f54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 469\n",
      "Length of val dataset: 118\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "split = int(len(dataset)*0.8)\n",
    "lengths = [split, len(dataset) - split]\n",
    "train_dataset, val_dataset = random_split(dataset, lengths)\n",
    "\n",
    "print(\"Length of train dataset:\", len(train_dataset))\n",
    "print(\"Length of val dataset:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bd82973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_dataset, val_dataset, collate_fn):\n",
    "    import torchvision\n",
    "    import torchvision.datasets as datasets\n",
    "    import torchvision.transforms as transforms   \n",
    "    batch_size = 10    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn = collate_fn)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size,collate_fn = collate_fn)    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "train_loader, val_loader = load_data(train_dataset, val_dataset, collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ca0cf8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=8, out_features=4, bias=True)\n",
      "  (fc2): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc3): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(8, 4) #None input size equals to the feature size of X\n",
    "        self.fc2 = nn.Linear(4, 2) #None\n",
    "        self.dropout = nn.Dropout(0.5) #None\n",
    "        self.fc3 = nn.Linear(2,1) #None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# initialize the NN\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4adabab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "criterion = nn.MSELoss()\n",
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.012, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "874ce950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "#input: Y_score,Y_pred,Y_true\n",
    "#output: accuracy, auc, precision, recall, f1-score\n",
    "def classification_metrics(Y_score, Y_pred, Y_true):\n",
    "    acc, auc, precision, recall, f1score = accuracy_score(Y_true, Y_pred), \\\n",
    "                                           roc_auc_score(Y_true, Y_score), \\\n",
    "                                           precision_score(Y_true, Y_pred), \\\n",
    "                                           recall_score(Y_true, Y_pred), \\\n",
    "                                           f1_score(Y_true, Y_pred)\n",
    "    return acc, auc, precision, recall, f1score\n",
    "\n",
    "\n",
    "\n",
    "#input: model, loader\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_y_true = torch.LongTensor()\n",
    "    #all_y_pred = torch.LongTensor()\n",
    "    all_y_score = torch.FloatTensor()\n",
    "    for x, y in loader:\n",
    "        y_hat = model(x.float())\n",
    "        # convert shape from [batch size, 1] to [batch size]\n",
    "        #y_hat = y_hat.view(y_hat.shape[0])\n",
    "        \"\"\"\n",
    "        TODO: obtain the predicted class (0, 1) by comparing y_hat against 0.5,\n",
    "        assign the predicted class to y_pred.\n",
    "        \"\"\"\n",
    "\n",
    "        #y_pred = torch.zeros(len(y_hat))\n",
    "        y = y\n",
    "\n",
    "        #for i in range(len(y_hat)):\n",
    "         #   if y_hat[i] >= 0.5:\n",
    "          #      y_pred[i] = 1\n",
    "           # else:\n",
    "            #    y_pred[i] = 0\n",
    "            \n",
    "        all_y_true = torch.cat((all_y_true, y.to('cpu').long()), dim=0)\n",
    "        #all_y_pred = torch.cat((all_y_pred,  y_pred.to('cpu').long()), dim=0)\n",
    "        all_y_score = torch.cat((all_y_score,  y_hat.to('cpu')), dim=0)\n",
    "        \n",
    "    MSE = mean_squared_error(all_y_true.detach().numpy(), all_y_score.detach().numpy() )\n",
    "    #acc, auc, precision, recall, f1 = classification_metrics(all_y_score.detach().numpy(), \n",
    "     #                                                        all_y_pred.detach().numpy(), \n",
    "      #                                                       all_y_true.detach().numpy())\n",
    "    #print(f\"acc: {acc:.3f}, auc: {auc:.3f}, precision: {precision:.3f}, recall: {recall:.3f}, f1: {f1:.3f}\")\n",
    "    #return acc, auc, precision, recall, f1\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15d6d9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ln/tfnp7jpd7fqfkj79wjz21nb00000gn/T/ipykernel_30896/3764957986.py:4: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  x = torch.tensor(sequences, dtype=torch.long)\n",
      "/Users/lomischen/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/lomischen/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([9])) that is different to the input size (torch.Size([9, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/var/folders/ln/tfnp7jpd7fqfkj79wjz21nb00000gn/T/ipykernel_30896/3764957986.py:4: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  x = torch.tensor(sequences, dtype=torch.long)\n",
      "/Users/lomischen/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15266.2559, grad_fn=<MseLossBackward0>)\n",
      "tensor(8066.5586, grad_fn=<MseLossBackward0>)\n",
      "tensor(14826.9990, grad_fn=<MseLossBackward0>)\n",
      "tensor(8614.6895, grad_fn=<MseLossBackward0>)\n",
      "tensor(7741.5142, grad_fn=<MseLossBackward0>)\n",
      "tensor(6667.5264, grad_fn=<MseLossBackward0>)\n",
      "tensor(18705.3398, grad_fn=<MseLossBackward0>)\n",
      "tensor(4213.3794, grad_fn=<MseLossBackward0>)\n",
      "tensor(3054.1978, grad_fn=<MseLossBackward0>)\n",
      "tensor(3148.7744, grad_fn=<MseLossBackward0>)\n",
      "tensor(3989.9846, grad_fn=<MseLossBackward0>)\n",
      "tensor(5911.6919, grad_fn=<MseLossBackward0>)\n",
      "tensor(4264.0103, grad_fn=<MseLossBackward0>)\n",
      "tensor(7449.2261, grad_fn=<MseLossBackward0>)\n",
      "tensor(7007.2046, grad_fn=<MseLossBackward0>)\n",
      "tensor(2280.5122, grad_fn=<MseLossBackward0>)\n",
      "tensor(4740.8511, grad_fn=<MseLossBackward0>)\n",
      "tensor(2229.7368, grad_fn=<MseLossBackward0>)\n",
      "tensor(4305.8989, grad_fn=<MseLossBackward0>)\n",
      "tensor(10203.0723, grad_fn=<MseLossBackward0>)\n",
      "tensor(7870.3052, grad_fn=<MseLossBackward0>)\n",
      "tensor(3738.7988, grad_fn=<MseLossBackward0>)\n",
      "tensor(10821.9004, grad_fn=<MseLossBackward0>)\n",
      "tensor(11649.2100, grad_fn=<MseLossBackward0>)\n",
      "tensor(10684.8564, grad_fn=<MseLossBackward0>)\n",
      "tensor(5654.2002, grad_fn=<MseLossBackward0>)\n",
      "tensor(20819.1855, grad_fn=<MseLossBackward0>)\n",
      "tensor(8144.9238, grad_fn=<MseLossBackward0>)\n",
      "tensor(4212.5142, grad_fn=<MseLossBackward0>)\n",
      "tensor(6244.3379, grad_fn=<MseLossBackward0>)\n",
      "tensor(9385.0996, grad_fn=<MseLossBackward0>)\n",
      "tensor(10965.1514, grad_fn=<MseLossBackward0>)\n",
      "tensor(4013.5256, grad_fn=<MseLossBackward0>)\n",
      "tensor(13350.0625, grad_fn=<MseLossBackward0>)\n",
      "tensor(8134.9189, grad_fn=<MseLossBackward0>)\n",
      "tensor(13201.7412, grad_fn=<MseLossBackward0>)\n",
      "tensor(5630.4448, grad_fn=<MseLossBackward0>)\n",
      "tensor(9166.1367, grad_fn=<MseLossBackward0>)\n",
      "tensor(13884.5088, grad_fn=<MseLossBackward0>)\n",
      "tensor(14323.4785, grad_fn=<MseLossBackward0>)\n",
      "tensor(17345.2891, grad_fn=<MseLossBackward0>)\n",
      "tensor(16552.0254, grad_fn=<MseLossBackward0>)\n",
      "tensor(2841.3127, grad_fn=<MseLossBackward0>)\n",
      "tensor(1504.1061, grad_fn=<MseLossBackward0>)\n",
      "tensor(8159.5806, grad_fn=<MseLossBackward0>)\n",
      "tensor(4621.9526, grad_fn=<MseLossBackward0>)\n",
      "tensor(18968.8887, grad_fn=<MseLossBackward0>)\n",
      "Epoch: 0 \tTraining Loss: 8607.997431\n",
      "tensor(2521.2000, grad_fn=<MseLossBackward0>)\n",
      "tensor(14892.4004, grad_fn=<MseLossBackward0>)\n",
      "tensor(3405.6001, grad_fn=<MseLossBackward0>)\n",
      "tensor(1363.2000, grad_fn=<MseLossBackward0>)\n",
      "tensor(4600., grad_fn=<MseLossBackward0>)\n",
      "tensor(5217.3999, grad_fn=<MseLossBackward0>)\n",
      "tensor(2336.3999, grad_fn=<MseLossBackward0>)\n",
      "tensor(10003.7002, grad_fn=<MseLossBackward0>)\n",
      "tensor(2273.7000, grad_fn=<MseLossBackward0>)\n",
      "tensor(8960.9004, grad_fn=<MseLossBackward0>)\n",
      "tensor(5550.2002, grad_fn=<MseLossBackward0>)\n",
      "tensor(5561.7002, grad_fn=<MseLossBackward0>)\n",
      "tensor(3467.4395, grad_fn=<MseLossBackward0>)\n",
      "tensor(6048.8999, grad_fn=<MseLossBackward0>)\n",
      "tensor(7424.9785, grad_fn=<MseLossBackward0>)\n",
      "tensor(2143.6177, grad_fn=<MseLossBackward0>)\n",
      "tensor(29470.3730, grad_fn=<MseLossBackward0>)\n",
      "tensor(8168.6211, grad_fn=<MseLossBackward0>)\n",
      "tensor(9998.4189, grad_fn=<MseLossBackward0>)\n",
      "tensor(18229.7227, grad_fn=<MseLossBackward0>)\n",
      "tensor(13321.5146, grad_fn=<MseLossBackward0>)\n",
      "tensor(4076.5066, grad_fn=<MseLossBackward0>)\n",
      "tensor(8904.1084, grad_fn=<MseLossBackward0>)\n",
      "tensor(2951.1047, grad_fn=<MseLossBackward0>)\n",
      "tensor(9722.5088, grad_fn=<MseLossBackward0>)\n",
      "tensor(3937.5042, grad_fn=<MseLossBackward0>)\n",
      "tensor(6036.5044, grad_fn=<MseLossBackward0>)\n",
      "tensor(5962.1045, grad_fn=<MseLossBackward0>)\n",
      "tensor(2848.8027, grad_fn=<MseLossBackward0>)\n",
      "tensor(12295.2051, grad_fn=<MseLossBackward0>)\n",
      "tensor(20879.2051, grad_fn=<MseLossBackward0>)\n",
      "tensor(9919.2051, grad_fn=<MseLossBackward0>)\n",
      "tensor(17596.0059, grad_fn=<MseLossBackward0>)\n",
      "tensor(6633.9038, grad_fn=<MseLossBackward0>)\n",
      "tensor(1880.8022, grad_fn=<MseLossBackward0>)\n",
      "tensor(6597.4023, grad_fn=<MseLossBackward0>)\n",
      "tensor(15736.0059, grad_fn=<MseLossBackward0>)\n",
      "tensor(5994.9019, grad_fn=<MseLossBackward0>)\n",
      "tensor(15577.0010, grad_fn=<MseLossBackward0>)\n",
      "tensor(5278.1025, grad_fn=<MseLossBackward0>)\n",
      "tensor(11479.1025, grad_fn=<MseLossBackward0>)\n",
      "tensor(8137.7026, grad_fn=<MseLossBackward0>)\n",
      "tensor(8734.5010, grad_fn=<MseLossBackward0>)\n",
      "tensor(12426.7021, grad_fn=<MseLossBackward0>)\n",
      "tensor(6951.0024, grad_fn=<MseLossBackward0>)\n",
      "tensor(15749.4023, grad_fn=<MseLossBackward0>)\n",
      "tensor(10900.3350, grad_fn=<MseLossBackward0>)\n",
      "tensor(20704.5020, grad_fn=<MseLossBackward0>)\n",
      "tensor(8287.0010, grad_fn=<MseLossBackward0>)\n",
      "tensor(6368.1025, grad_fn=<MseLossBackward0>)\n",
      "tensor(4675.8013, grad_fn=<MseLossBackward0>)\n",
      "tensor(19095.8008, grad_fn=<MseLossBackward0>)\n",
      "tensor(3760.9019, grad_fn=<MseLossBackward0>)\n",
      "tensor(10135.2012, grad_fn=<MseLossBackward0>)\n",
      "tensor(12033.6016, grad_fn=<MseLossBackward0>)\n",
      "tensor(4511.3008, grad_fn=<MseLossBackward0>)\n",
      "tensor(10297.2002, grad_fn=<MseLossBackward0>)\n",
      "tensor(8092.1011, grad_fn=<MseLossBackward0>)\n",
      "tensor(8456.0010, grad_fn=<MseLossBackward0>)\n",
      "tensor(6904.5005, grad_fn=<MseLossBackward0>)\n",
      "tensor(2198.7002, grad_fn=<MseLossBackward0>)\n",
      "tensor(14309.2998, grad_fn=<MseLossBackward0>)\n",
      "tensor(8793.4014, grad_fn=<MseLossBackward0>)\n",
      "tensor(1626.6003, grad_fn=<MseLossBackward0>)\n",
      "tensor(12906.8008, grad_fn=<MseLossBackward0>)\n",
      "tensor(5465.8008, grad_fn=<MseLossBackward0>)\n",
      "tensor(10472.7002, grad_fn=<MseLossBackward0>)\n",
      "tensor(5160.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor(5059.8008, grad_fn=<MseLossBackward0>)\n",
      "tensor(9900., grad_fn=<MseLossBackward0>)\n",
      "tensor(5325.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(9491., grad_fn=<MseLossBackward0>)\n",
      "tensor(6373.2007, grad_fn=<MseLossBackward0>)\n",
      "tensor(9771.5996, grad_fn=<MseLossBackward0>)\n",
      "tensor(11773.5996, grad_fn=<MseLossBackward0>)\n",
      "tensor(4618.8003, grad_fn=<MseLossBackward0>)\n",
      "tensor(6489., grad_fn=<MseLossBackward0>)\n",
      "tensor(1649.5004, grad_fn=<MseLossBackward0>)\n",
      "tensor(11505., grad_fn=<MseLossBackward0>)\n",
      "tensor(21045., grad_fn=<MseLossBackward0>)\n",
      "tensor(11657.2998, grad_fn=<MseLossBackward0>)\n",
      "tensor(4631.2002, grad_fn=<MseLossBackward0>)\n",
      "tensor(14708., grad_fn=<MseLossBackward0>)\n",
      "tensor(1471.0006, grad_fn=<MseLossBackward0>)\n",
      "tensor(5557., grad_fn=<MseLossBackward0>)\n",
      "tensor(9076.0996, grad_fn=<MseLossBackward0>)\n",
      "tensor(13907., grad_fn=<MseLossBackward0>)\n",
      "tensor(7831.6001, grad_fn=<MseLossBackward0>)\n",
      "tensor(2395.1003, grad_fn=<MseLossBackward0>)\n",
      "tensor(9003.0996, grad_fn=<MseLossBackward0>)\n",
      "tensor(10192.0996, grad_fn=<MseLossBackward0>)\n",
      "tensor(6620., grad_fn=<MseLossBackward0>)\n",
      "tensor(8098.2002, grad_fn=<MseLossBackward0>)\n",
      "tensor(7817.2222, grad_fn=<MseLossBackward0>)\n",
      "tensor(25625.0996, grad_fn=<MseLossBackward0>)\n",
      "tensor(9911.5996, grad_fn=<MseLossBackward0>)\n",
      "tensor(2611.3003, grad_fn=<MseLossBackward0>)\n",
      "tensor(8628., grad_fn=<MseLossBackward0>)\n",
      "tensor(2129.9004, grad_fn=<MseLossBackward0>)\n",
      "tensor(14111., grad_fn=<MseLossBackward0>)\n",
      "tensor(5508.2998, grad_fn=<MseLossBackward0>)\n",
      "tensor(5359.2002, grad_fn=<MseLossBackward0>)\n",
      "tensor(31180.6992, grad_fn=<MseLossBackward0>)\n",
      "tensor(12128.5996, grad_fn=<MseLossBackward0>)\n",
      "tensor(3574.8000, grad_fn=<MseLossBackward0>)\n",
      "tensor(3107.2002, grad_fn=<MseLossBackward0>)\n",
      "tensor(3122.3000, grad_fn=<MseLossBackward0>)\n",
      "tensor(5932., grad_fn=<MseLossBackward0>)\n",
      "tensor(26595.8008, grad_fn=<MseLossBackward0>)\n",
      "tensor(18346.0996, grad_fn=<MseLossBackward0>)\n",
      "tensor(4926.2998, grad_fn=<MseLossBackward0>)\n",
      "tensor(11808.7998, grad_fn=<MseLossBackward0>)\n",
      "tensor(6328.7002, grad_fn=<MseLossBackward0>)\n",
      "tensor(6072.2002, grad_fn=<MseLossBackward0>)\n",
      "tensor(10832.7998, grad_fn=<MseLossBackward0>)\n",
      "tensor(4989.8999, grad_fn=<MseLossBackward0>)\n",
      "tensor(6174.6001, grad_fn=<MseLossBackward0>)\n",
      "tensor(6359.8999, grad_fn=<MseLossBackward0>)\n",
      "tensor(9755.0996, grad_fn=<MseLossBackward0>)\n",
      "tensor(3983.7002, grad_fn=<MseLossBackward0>)\n",
      "tensor(10493., grad_fn=<MseLossBackward0>)\n",
      "tensor(5070.2002, grad_fn=<MseLossBackward0>)\n",
      "tensor(14936.7002, grad_fn=<MseLossBackward0>)\n",
      "tensor(3546.8000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7432.1001, grad_fn=<MseLossBackward0>)\n",
      "tensor(2242.3999, grad_fn=<MseLossBackward0>)\n",
      "tensor(9449.7002, grad_fn=<MseLossBackward0>)\n",
      "tensor(11276.4004, grad_fn=<MseLossBackward0>)\n",
      "tensor(4216.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7752.8999, grad_fn=<MseLossBackward0>)\n",
      "tensor(4216.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(1872.8000, grad_fn=<MseLossBackward0>)\n",
      "tensor(12770.2998, grad_fn=<MseLossBackward0>)\n",
      "tensor(9638.7998, grad_fn=<MseLossBackward0>)\n",
      "tensor(4727.1001, grad_fn=<MseLossBackward0>)\n",
      "tensor(14708.4004, grad_fn=<MseLossBackward0>)\n",
      "tensor(2579.6001, grad_fn=<MseLossBackward0>)\n",
      "tensor(5267.7998, grad_fn=<MseLossBackward0>)\n",
      "tensor(6346.2998, grad_fn=<MseLossBackward0>)\n",
      "tensor(7900., grad_fn=<MseLossBackward0>)\n",
      "tensor(4324.7778, grad_fn=<MseLossBackward0>)\n",
      "tensor(8378.2998, grad_fn=<MseLossBackward0>)\n",
      "tensor(3136.6001, grad_fn=<MseLossBackward0>)\n",
      "tensor(3901.3000, grad_fn=<MseLossBackward0>)\n",
      "tensor(9021.7002, grad_fn=<MseLossBackward0>)\n",
      "tensor(18837.1992, grad_fn=<MseLossBackward0>)\n",
      "tensor(10545.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7624.2002, grad_fn=<MseLossBackward0>)\n",
      "tensor(8072.3999, grad_fn=<MseLossBackward0>)\n",
      "tensor(14583.7002, grad_fn=<MseLossBackward0>)\n",
      "tensor(6333.2998, grad_fn=<MseLossBackward0>)\n",
      "tensor(2883.8000, grad_fn=<MseLossBackward0>)\n",
      "tensor(11940.5996, grad_fn=<MseLossBackward0>)\n",
      "tensor(6649.2002, grad_fn=<MseLossBackward0>)\n",
      "tensor(2202., grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8044.7002, grad_fn=<MseLossBackward0>)\n",
      "tensor(6070.2002, grad_fn=<MseLossBackward0>)\n",
      "tensor(3784.2000, grad_fn=<MseLossBackward0>)\n",
      "tensor(14248.2002, grad_fn=<MseLossBackward0>)\n",
      "tensor(3848.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(7321.2002, grad_fn=<MseLossBackward0>)\n",
      "tensor(8205.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(8662.5996, grad_fn=<MseLossBackward0>)\n",
      "tensor(5324.3999, grad_fn=<MseLossBackward0>)\n",
      "tensor(10826.7998, grad_fn=<MseLossBackward0>)\n",
      "tensor(8611.7002, grad_fn=<MseLossBackward0>)\n",
      "tensor(5314.2002, grad_fn=<MseLossBackward0>)\n",
      "tensor(10284.2002, grad_fn=<MseLossBackward0>)\n",
      "tensor(4912.2002, grad_fn=<MseLossBackward0>)\n",
      "tensor(3110.7000, grad_fn=<MseLossBackward0>)\n",
      "tensor(16676.8008, grad_fn=<MseLossBackward0>)\n",
      "tensor(11357., grad_fn=<MseLossBackward0>)\n",
      "tensor(5223.2002, grad_fn=<MseLossBackward0>)\n",
      "tensor(4915., grad_fn=<MseLossBackward0>)\n",
      "tensor(19362.4004, grad_fn=<MseLossBackward0>)\n",
      "tensor(3050.8000, grad_fn=<MseLossBackward0>)\n",
      "tensor(2419.3000, grad_fn=<MseLossBackward0>)\n",
      "tensor(4661.6001, grad_fn=<MseLossBackward0>)\n",
      "tensor(21675.5996, grad_fn=<MseLossBackward0>)\n",
      "tensor(8650.5996, grad_fn=<MseLossBackward0>)\n",
      "tensor(14784.4004, grad_fn=<MseLossBackward0>)\n",
      "tensor(4801.2002, grad_fn=<MseLossBackward0>)\n",
      "tensor(3770.2000, grad_fn=<MseLossBackward0>)\n",
      "tensor(11777.5996, grad_fn=<MseLossBackward0>)\n",
      "tensor(16208.7002, grad_fn=<MseLossBackward0>)\n",
      "tensor(19319.8008, grad_fn=<MseLossBackward0>)\n",
      "tensor(4240.1001, grad_fn=<MseLossBackward0>)\n",
      "tensor(4296.7778, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lomischen/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([9])) that is different to the input size (torch.Size([9, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "# feel free to change this (just make sure that Coursera does not timeout)\n",
    "n_epochs = 5\n",
    "\n",
    "# prep model for training\n",
    "model.train()\n",
    "\n",
    "train_loss_arr = []\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    train_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        \"\"\" Step 1. clear gradients \"\"\"\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \"\"\" \n",
    "        TODO: Step 2. perform forward pass using `model`, save the output to y_hat;\n",
    "              Step 3. calculate the loss using `criterion`, save the output to loss.\n",
    "        \"\"\"\n",
    "        y_hat = model.forward(x.float()) #None\n",
    "        #print(y_hat)\n",
    "        #y = y.unsqueeze(1)\n",
    "        \n",
    "        loss = criterion(y_hat,y)#None\n",
    "        print(loss)\n",
    "        \n",
    "        \"\"\" Step 4. backward pass \"\"\"\n",
    "        loss.backward()\n",
    "        \"\"\" Step 5. optimization \"\"\"\n",
    "        optimizer.step()\n",
    "        \"\"\" Step 6. record loss \"\"\"\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    if epoch % 20 == 0:\n",
    "        train_loss_arr.append(np.mean(train_loss))\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
    "        evaluate(model, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e75c9c",
   "metadata": {},
   "source": [
    "## Computational Requirements:\n",
    "\n",
    "Since the model created does not encapsulate all of the input features called for in the original paper, training and running the model was actually rather computational feasible. The paper was done using a regular mac air 13\" 8 core CPU and no local/cloud GPU was required. The total runtime for training and evaluating the data took about ~ 5mins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb493f3",
   "metadata": {},
   "source": [
    "## Result discussion\n",
    "Unfortunately plenty of the time was spent on searching, prepping, and transforming data and mot much time was left for the actual model training and I'm still working towards debugging the code. So as of now there isn't sufficient result to share with the group. \n",
    "\n",
    "However once we finish debug the model, the next steps is to expand the dataset, supplement inputs with other feature selection, and train a few more models as per the paper ( e.g SVM and other DNNs with multiple layers) and compare their relevant result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d0522f",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "Given the limitation of the data access as well as the ambiguity of data sources, the original paper was not successfully reproduced. To elaborate further, the struggle with data access was under 2 folds. For one, the 2nd dimension of the input feature X came under the XML format which was unconvertable to CSV for ease of analyitics despite spending extensive effort in doing so; second, the 3rd dimention of input feature X that involves using biomedical literature as inputs that was supposedly derived and scraped from thousands and millions of literatures without concrete references and pointers on how to do so made it impossible to repro. This means reproducing the result was deem to be a struggle. This also means that while a base model in attempt to repro the model was created, the results should be closely examined\n",
    "\n",
    "What was easy\n",
    "-- The research plan/goal as well as the overall experiments were relatively easy to comprehend. This means that I did not spend too much time and effort in attempt to understand what's being built and why/what except with the hows. Also we fortunately have in class experience building the base model that the paper used. So overall despite the fact that I was not able to repro the paper properly, it's still a paper that's relatively easy to comprehend where techniques learn from this class and previous classes were applicable. And with that base comprehension, I'd expect other scholars and ML researchers to be able to learn from it and extend on what's been done\n",
    "\n",
    "\n",
    "What was difficult\n",
    "-- The difficult portion boils down to multiple folds. Accessing data is at the top -- the features of X are scattered across multiple database and they require significant effort in cleaning and preprocessing. Not only that, even with accessiable data, not all of the features used and referenced in the paper were readily available. On top of that, there were no clear instructions and indication on what biomedical literatures were used as the 3rd input dimension of X especially when that was deemed to be the most contextual and helpful in training the data. \n",
    "\n",
    "\n",
    "Recommnendations to the orignnal authors for improving reproducibility\n",
    "-- Suppose that enabling readers and other scholars to reproduce this paper is part of the authors' goals, I'd like to propose the authors to share or to provide clearer indication and instruction on how/where to access and clean the data so that others who are looking to repro the research could align with what's being used in the research paper. In addition to that, I'd also noticed that throughout the lab, the computational requiremenets for data pre-processing and training was slightly more demanding than what I'd anticipated. If the authors were able to provide some form of baseline or guidedance on CPU/GPU requirements, that would have made repro-ing the study a lot easier too.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae039b7",
   "metadata": {},
   "source": [
    "## Data download instructions\n",
    "\n",
    "1) Y -- retrieved from SIDER: http://sideeffects.embl.de/download/. One could read more about the download files via drug_names.tsv and drug_atc.tsv. The zipped file of meddra_all_indications.tsv.gz contains drug name and their relevant ADRs. Joining is required to join Y data across multiple years.\n",
    "\n",
    "2) 1st dimension of input feature X -- retrieved from PubChem: https://pubchem.ncbi.nlm.nih.gov/classification/#hid=72. One could click into the section of Chemical and Physical Properties and download the data of interest. The downloaded data contains about 3/4 of the inputs required for the actual research. Cleaning and pre-processing is required \n",
    "\n",
    "3) 2nd dimension of input feature X: retrieved from DrugBank: https://go.drugbank.com/releases/latest. One would need to request special academic access before XML data could be downloaded. \n",
    "\n",
    "\n",
    "4) 3rd dimension of input feature X: (unknown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d50364b",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "There's no code repo shown in the original research, so there was nothing for us to build off from and everything was completed from scratch\n",
    "\n",
    "Original paper: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6381404/ ; \n",
    "PubChem database for chemical & phyiscal properties: https://pubchem.ncbi.nlm.nih.gov/classification/#hid=72 ;\n",
    "DrugBank for bio properites: https://go.drugbank.com/releases/latest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bc323f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
